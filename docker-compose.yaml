version: "3.8"
services:
  server:
    runtime: nvidia
    image: nvcr.io/nvidia/tritonserver:20.06-py3
    ports: 
      - "8000-8002:8000-8002"
    volumes:
      - ./models:/models/
    shm_size: 1g
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    command: tritonserver --model-repository=/models --strict-model-config=false --log-verbose=1
    healthcheck:
      test: curl -v localhost:8000/v2/health/ready
      interval: 30s
      timeout: 10s
      retries: 5
  client:
    runtime: nvidia
    build:
        context: client
        dockerfile: Dockerfile
    volumes:
      - ./client:/app/
      - /opt/samples/:/app/samples/
      - /tmp/.X11-unix:/tmp/.X11-unix
    environment:
      - DISPLAY=$DISPLAY
    shm_size: 1g
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    working_dir: /app
    command: 'python3 detect.py'
    depends_on:
      server:
        condition: service_healthy